{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "summarization_task.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2hMkLOHcdDYD"
      ],
      "authorship_tag": "ABX9TyOZxT4zfakPqBINR6U6rHK7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kperv/summarizer_app/blob/main/summarization_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MU0iFZgkUUPY"
      },
      "source": [
        "# ***Extractive summarization task***\n",
        "\n",
        "### Main highlights\n",
        "\n",
        "*   Supported languages are Russian and Spanish.\n",
        "*   Text is broken into sentences by Spacy.\n",
        "*   Sentences are tokenized by pretrained BertTokenizer.\n",
        "*   Framework PyTorch (PyTorch Lightning)\n",
        "\n",
        "\n",
        "### Neural Net architecture\n",
        "\n",
        "The attempted idea is to train a centroid in a vector space by using Stacked Convolutional Layers.\n",
        "\n",
        "### Benchmark\n",
        "\n",
        "Apply clustering algorithm on aggregated word vectors to get the result fast.\n",
        "\n",
        "### Metric is Bert_Score\n",
        "\n",
        "\n",
        "*   Supports target languages\n",
        "*   Based on vector distance, which is better suited for the task\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUm8yudmR_MD"
      },
      "source": [
        "# **Installations and imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx0ou6jEKC-q"
      },
      "source": [
        "%%capture\n",
        "!pip install transformers[sentencepiece]\n",
        "!pip install pytorch-lightning\n",
        "!pip install -U bert_score\n",
        "!pip install datasets\n",
        "!pip install https://huggingface.co/spacy/ru_core_news_md/resolve/main/ru_core_news_md-any-py3-none-any.whl\n",
        "!pip install https://huggingface.co/spacy/es_core_news_md/resolve/main/es_core_news_md-any-py3-none-any.whl\n",
        "\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import spacy\n",
        "import transformers\n",
        "import datasets\n",
        "import pytorch_lightning as pl\n",
        "import bert_score\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
        "from datasets import load_dataset\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from bert_score import score\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKZ6fnY5ceqM"
      },
      "source": [
        "pl.seed_everything(42)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hMkLOHcdDYD"
      },
      "source": [
        "## requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngTniRZGclMv",
        "outputId": "23d9a141-a221-4a8b-de1c-ff7ee9ea52f8"
      },
      "source": [
        "print(\"Spacy = \", spacy.__version__)\n",
        "print(\"torch = \", torch.__version__)\n",
        "print(\"numpy = \", np.__version__)\n",
        "print(\"datasets = \", datasets.__version__)\n",
        "print(\"Transformers = \", transformers.__version__)\n",
        "print(\"PyTorch Lightning = \", pl.__version__)\n",
        "print(\"Spacy = \", spacy.__version__)\n",
        "print(\"Bert Score = \", bert_score.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spacy =  3.1.1\n",
            "torch =  1.9.0+cu102\n",
            "numpy =  1.19.5\n",
            "datasets =  1.11.0\n",
            "Transformers =  4.9.2\n",
            "PyTorch Lightning =  1.4.2\n",
            "Spacy =  3.1.1\n",
            "Bert Score =  0.3.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DR8qesSYuku"
      },
      "source": [
        "## Examples and checks of Bert score\n",
        "\n",
        "Predictions correspond to a news headline and references to a ferst paragraph of the same article. Expected to get high scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSehe4b1ZsYd",
        "outputId": "66c76714-8670-4cc6-8c9a-a863eeb9d51f"
      },
      "source": [
        "predictions = [\"Аналитик прокомментировал предстоящий визит Меркель в Москву\"]\n",
        "references = [\"Ведущий научный сотрудник Центра германских исследований Института Европы РАН Александр Камкин прокомментировал в беседе с RT сообщение о том, что канцлер Германии Ангела Меркель и президент России Владимир Путин проведут переговоры в Москве 20 августа\"]\n",
        "P, R, F1 = score(predictions, references, lang='ru')\n",
        "print(f\"System level F1 score: {F1.mean():.3f}\")\n",
        "print(f\"System level P score: {P.mean():.3f}\")\n",
        "print(f\"System level R score: {R.mean():.3f}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "System level F1 score: 0.680\n",
            "System level P score: 0.738\n",
            "System level R score: 0.632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQU3ilktYSCP",
        "outputId": "c1d039da-52bc-456f-f604-bc1614c61d6e"
      },
      "source": [
        "predictions = [\"Qué sabemos sobre el diálogo entre la oposición y Maduro que está programado para comenzar este viernes en México\"]\n",
        "references = [\"Tras años de tensiones, protestas y negociaciones estancadas, en medio de una situación económica muy deteriorada y complicada aún más por la pandemia de covid-19, el gobierno de Venezuela y la oposición intentará por quinta vez llegar a una solución para la crisis política mediante un diálogo, esta vez en México.\"]\n",
        "P, R, F1 = score(predictions, references, lang='es')\n",
        "print(f\"System level F1 score: {F1.mean():.3f}\")\n",
        "print(f\"System level P score: {P.mean():.3f}\")\n",
        "print(f\"System level R score: {R.mean():.3f}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "System level F1 score: 0.636\n",
            "System level P score: 0.663\n",
            "System level R score: 0.611\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFoWqcpUaBBF"
      },
      "source": [
        "## **Dataset is large-scale MultiLingual SUMmarization dataset**\n",
        "\n",
        "### Main info:\n",
        "\n",
        "**es**\n",
        "\n",
        "Size of downloaded dataset files: 489.53 MB\n",
        "\n",
        "Size of the generated dataset: 1274.55 MB\n",
        "\n",
        "Total amount of disk used: 1764.09 MB\n",
        "\n",
        "**Data Splits:** Train 266367\tVal 10358\tTest 1392\n",
        "\n",
        "\n",
        "\n",
        "**ru**\n",
        "\n",
        "Size of downloaded dataset files: 101.30 MB\n",
        "\n",
        "Size of the generated dataset: 263.38 MB\n",
        "\n",
        "Total amount of disk used: 364.68 MB\n",
        "\n",
        "**Data Splits:** Train 25556\tVal 750\tTest 757"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r16fuKERbYk6"
      },
      "source": [
        "%%capture\n",
        "dataset_ru = load_dataset(\"mlsum\", \"ru\")\n",
        "dataset_es = load_dataset(\"mlsum\", \"es\")\n",
        "\n",
        "nlp_ru = spacy.load(\"ru_core_news_md\")\n",
        "nlp_es = spacy.load(\"es_core_news_md\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkKtDKB0EuWV",
        "outputId": "4dce2513-4ce5-4d18-acaa-033ba39b306d"
      },
      "source": [
        "dataset_ru.num_rows"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test': 757, 'train': 25556, 'validation': 750}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wzwfhQFf9UO"
      },
      "source": [
        "# ***Clustering solution***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSMlaerOJj73"
      },
      "source": [
        "def break_text(text):\n",
        "  doc = nlp_es(text)\n",
        "  assert doc.has_annotation(\"SENT_START\")\n",
        "  sentences = [str(sent) for sent in doc.sents]\n",
        "  return sentences"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jbh87iDvfV9d"
      },
      "source": [
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdhCFHFS6IPq"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "model = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "encoded_sentences = tokenizer(predictions, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "#decoded_string = tokenizer.decode(encoded_sentences.input_ids[0])\n",
        "outputs = model(encoded_sentences.input_ids)\n",
        "embeddings = outputs.last_hidden_state"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPRcOGWPdOXk"
      },
      "source": [
        "\n",
        "#tokenized_sents = []\n",
        "#ids = []\n",
        "#for sent in break_text(text):\n",
        "#  tokens = tokenizer.tokenize(sent)\n",
        "#  tokenized_sents.append(tokens)\n",
        "#  id = tokenizer.convert_tokens_to_ids(tokens)\n",
        "#  ids.append(id)\n",
        "#input_ids = torch.tensor([ids[0]])\n",
        "#input_ids"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLyLBzsvebSi"
      },
      "source": [
        "## *Check for long training*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnhoxWL9L6Mb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b922aa9-d2ef-4b0c-c0d5-5c7e60f5aaeb"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msFS5JIhE24t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5e6ecc0-d040-4216-dd80-d5a5ef85f4fe"
      },
      "source": [
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "device"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUtdUd34eRcj"
      },
      "source": [
        "# ***Neural Net solution***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wU7Qfxuvqt2_"
      },
      "source": [
        "class MlSumDataModule(pl.LightningDataModule):\n",
        "  def __init__(self, batch_size=32):\n",
        "    super.__init__()\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "  def prepare_data(self):\n",
        "    self.dataset_ru = load_dataset(\"mlsum\", \"ru\")\n",
        "    self.dataset_es = load_dataset(\"mlsum\", \"es\")\n",
        "    nlp_ru = spacy.load(\"ru_core_news_md\")\n",
        "    nlp_es = spacy.load(\"es_core_news_md\")\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    dataset_ru_train = DataLoader(\n",
        "        self.dataset_ru[\"train\"], \n",
        "        batch_size=self.batch_size)\n",
        "    dataset_es_train = DataLoader(\n",
        "        self.dataset_es[\"train\"], \n",
        "        batch_size=self.batch_size)\n",
        "    loaders = [dataset_ru_train, dataset_es_train]\n",
        "    return train_loaders\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    dataset_ru_val = DataLoader(\n",
        "        self.dataset_ru[\"val\"], \n",
        "        batch_size=self.batch_size)\n",
        "    dataset_es_val = DataLoader(\n",
        "        self.dataset_es[\"val\"], \n",
        "        batch_size=self.batch_size)\n",
        "    loaders = [dataset_ru_val, dataset_es_val]\n",
        "    return val_loaders\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    dataset_ru_test = DataLoader(\n",
        "        self.dataset_ru[\"test\"], \n",
        "        batch_size=self.batch_size)\n",
        "    dataset_es_test = DataLoader(\n",
        "        self.dataset_es[\"test\"], \n",
        "        batch_size=self.batch_size)\n",
        "    loaders = [dataset_ru_test, dataset_es_test]\n",
        "    return test_loaders"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPERdAtikR9C"
      },
      "source": [
        "class Model(pl.LightningModule):\n",
        "  def __init__(self):\n",
        "    super.__init__()\n",
        "    self.l1 = nn.Linear(x, y)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.relu()\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    x, y = batch\n",
        "    y_hat = self(x)\n",
        "    loss = F.pairwise_distance(y_hat, y)\n",
        "    self.log(\"train_loss\", loss, on_epoch=True)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    x, y = batch\n",
        "    y_hat = self.model(x)\n",
        "    loss = F.pairwise_distance(y_hat, y)\n",
        "    self.log(\"val_loss\", loss, on_epoch=True)\n",
        "\n",
        "  def test_step(self, batch, batch_idx):\n",
        "    x, y = batch\n",
        "    y_hat = self.model(x)\n",
        "    loss = F.pairwise_distance(y_hat, y)\n",
        "    self.log(\"test_loss\", loss, on_epoch=True)\n",
        "\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    return torch.optim.Adam(self.parameters(), lr=self.lr)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNBevqlckJjh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "19543fb9-a0ba-4d3f-9e90-a59ae89eedee"
      },
      "source": [
        "trainer = pl.Trainer()\n",
        "model = Model()\n",
        "\n",
        "trainer.fit(model, train_loader)\n",
        "trainer.test(model, test_dataloaders=val_dataloader)\n",
        "trainer.test(test_dataloaders=test_dataloader)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-196e59dc7b0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# trainer.tune(model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-c8a4f4de7ba2>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: descriptor '__init__' of 'super' object needs an argument"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCpNjZhKoth2"
      },
      "source": [
        "# call after training\n",
        "trainer = pl.Trainer()\n",
        "trainer.fit(model)\n",
        "trainer.test(dataloaders=test_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRXa-YQ9o2AL"
      },
      "source": [
        "# or call with pretrained model\n",
        "model = MyLightningModule.load_from_checkpoint(PATH)\n",
        "trainer = pl.Trainer()\n",
        "trainer.test(model, dataloaders=test_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzSuPh2WFATb"
      },
      "source": [
        "# get predictions\n",
        "PATH = \"../saved_model\"\n",
        "my_model = Model.load_from_checkpoint(PATH)\n",
        "my_model.freeze()\n",
        "prediction = my_model(new_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQ9usfHRKhpv"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWLdiDjAnim1"
      },
      "source": [
        "# Further improvements\n",
        "\n",
        "\n",
        "\n",
        "*   Stack Convolution layers (similar to InceptionNet)\n",
        "*   Use Multi-Head Attention instead of CNNs (similar to Hie-BART)\n",
        "\n"
      ]
    }
  ]
}