{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMX/lb0SSU9aQViMcaAtxgi",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kperv/summarizer_app/blob/main/Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MU0iFZgkUUPY"
      },
      "source": [
        "# Summarization project\n",
        "\n",
        "for ods.ai *Natural Language Processing course*\n",
        "\n",
        "\n",
        "## Clustering sentence embeddings for text summarization\n",
        "\n",
        "\n",
        "*   Text is broken into sentences by Spacy\n",
        "*   Sentences are tokenized by pretrained BertTokenizer\n",
        "*   Word embeddings are collected brom Bert and averaged to get sentence embeddings\n",
        "*   sklearn is used for KMeans Clustering\n",
        "*   Evaluation metric is rouge\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUm8yudmR_MD"
      },
      "source": [
        "## Installations and imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install https://huggingface.co/spacy/ru_core_news_md/resolve/main/ru_core_news_md-any-py3-none-any.whl\n",
        "!pip install https://huggingface.co/spacy/es_core_news_md/resolve/main/es_core_news_md-any-py3-none-any.whl\n",
        "!git clone https://github.com/kperv/summarizer_app.git\n",
        "!pip install -r summarizer_app/requirements.txt"
      ],
      "metadata": {
        "id": "Knuxl1owmPpc"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx0ou6jEKC-q"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import spacy\n",
        "import nltk\n",
        "import transformers\n",
        "import datasets\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import pairwise_distances_argmin_min\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from rouge import Rouge"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKZ6fnY5ceqM"
      },
      "source": [
        "nlp = spacy.load(\"ru_core_news_md\")"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hMkLOHcdDYD"
      },
      "source": [
        "### requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngTniRZGclMv",
        "outputId": "2f9a8022-f2f1-45fd-9a6f-4c1609ddd5f6"
      },
      "source": [
        "print(\"numpy=={}\".format(np.__version__))\n",
        "print(\"spacy=={}\".format(spacy.__version__))\n",
        "print(\"transformers=={}\".format(transformers.__version__))\n",
        "print(\"sklearn=={}\".format(sklearn.__version__))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy==1.19.5\n",
            "spacy==3.2.1\n",
            "transformers==4.13.0\n",
            "sklearn==1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wzwfhQFf9UO"
      },
      "source": [
        "## Extractive text summarization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNawPZhp8rj1"
      },
      "source": [
        "number = 3\n",
        "lang='ru'"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cxlt98Mk3z7X"
      },
      "source": [
        "Some random paragraph from news"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zo61w0jKcjhw"
      },
      "source": [
        "text = \"Очень непросто делать прогнозы. С одной стороны, достаточно долго длится фаза подъема, после 11 июня началась третья волна в Свердловской области. Мы достигли очень высокого уровня заболеваемости и смертности и стабилизировались на нем. Как долго это будет продолжаться, зависит от доли восприимчивого к вирусу населения. На момент начала третьей волны число привитых или переболевших свердловчан не превышало 50 процентов, — отметил Соловьев. — Чтобы третья волна остановилась, мы должны достичь высокого уровня коллективного иммунитета. С помощью вакцинации мы уже не успеваем его достичь. Второй вариант — заболеваемость. Официальная статистика не отражает реальное число людей, которые встретились с коронавирусом. Сейчас приблизительно 65% жителей переболели или вакцинировались от коронавируса. Это должно сказываться на снижении заболеваемости, но пока этого не происходит.\""
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQGFkyWY4EEt"
      },
      "source": [
        "### Separate sentences with SpaCy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSMlaerOJj73"
      },
      "source": [
        "def break_text(text):\n",
        "  doc = nlp(text)\n",
        "  assert doc.has_annotation(\"SENT_START\")\n",
        "  sentences = [str(sent) for sent in doc.sents]\n",
        "  return sentences"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3Plc1nbb3WV"
      },
      "source": [
        "sentences = break_text(text)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrubThFD4O72"
      },
      "source": [
        "### Convert words to tokens and run through Bert encoder to get word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdhCFHFS6IPq"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "model = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "encoded_sentences = tokenizer(sentences, truncation=True, padding=True, return_tensors=\"pt\")\n",
        "outputs = model(encoded_sentences.input_ids)\n",
        "embeddings = outputs.last_hidden_state"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwUf2cNz4aM5"
      },
      "source": [
        "I'm using *mean* to get sentence embeddings. This step can be improved."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNres54shQab"
      },
      "source": [
        "embeddings = embeddings.detach().numpy()\n",
        "embeddings = embeddings.mean(axis=1)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CloV1lV85DmP"
      },
      "source": [
        "Cluster embeddings in a space into n (number) clusters to get centroids. Take distance metric between sentence embeddings and centroids and choose n closest to put into the summary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKnUPRCz5bdl"
      },
      "source": [
        "### Collect summary sentences together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UCKJWqdicsu"
      },
      "source": [
        "kmeans = KMeans(n_clusters=number).fit(embeddings)\n",
        "centroids = kmeans.cluster_centers_\n",
        "result = pairwise_distances_argmin_min(embeddings, centroids)\n",
        "summary_sent_positions = list(np.argsort(result[1])[:number])"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "J8eHo2qM2MoD",
        "outputId": "01e4b709-2ce9-4354-c14d-72123e12b7ec"
      },
      "source": [
        "summary = \"\"\n",
        "for idx in summary_sent_positions:\n",
        "  summary += sentences[idx]\n",
        "summary"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'На момент начала третьей волны число привитых или переболевших свердловчан не превышало 50 процентов, — отметил Соловьев.Очень непросто делать прогнозы.Как долго это будет продолжаться, зависит от доли восприимчивого к вирусу населения.'"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate solution on 200 samples"
      ],
      "metadata": {
        "id": "aN-lhRhqpvl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collect_modified_dataset(data_path):\n",
        "    transformed_df = pd.DataFrame()\n",
        "    for dataset_part in os.listdir(data_path):\n",
        "        part_path = os.path.join(data_path, dataset_part)\n",
        "        df_slice = pd.read_csv(part_path)\n",
        "        transformed_df = pd.concat([transformed_df, df_slice])\n",
        "    return transformed_df"
      ],
      "metadata": {
        "id": "wpwWNqMWhHaH"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rouge_score(sample):\n",
        "    rouge = Rouge()\n",
        "    preprocess_exs = lambda exs : [ex.strip().lower() for ex in exs]\n",
        "    predictions = []\n",
        "    predictions.append(sample['summary'])\n",
        "    predictions = preprocess_exs(predictions)\n",
        "    references = []\n",
        "    references.append(sample.text)\n",
        "    references = preprocess_exs(references)\n",
        "    predictions = [pred if len(pred) else 'а' for pred in predictions]\n",
        "    rouge_scores =  rouge.get_scores(predictions, references, avg=True)\n",
        "    return {k: v['f'] * 100 for k, v in rouge_scores.items()}"
      ],
      "metadata": {
        "id": "XibjaC2OoxPc"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_metrics(dataset):\n",
        "    dataset = dataset.loc[:, ['text', 'summary']]\n",
        "    dataset[['rouge-1', 'rouge-2', 'rouge-l']] = 0, 0, 0\n",
        "    df = pd.DataFrame(list(dataset.apply(get_rouge_score, axis=1).values))\n",
        "    dataset = df.combine_first(dataset)\n",
        "    dataset = dataset.reindex(\n",
        "        columns=['text', 'summary', 'rouge-1', 'rouge-2', 'rouge-l']\n",
        "    )\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "7zcKjpdaoxSi"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = os.getcwd()\n",
        "data_path = data_dir + \"/summarizer_app/data\"\n",
        "df = collect_modified_dataset(data_path)\n",
        "df = add_metrics(df)"
      ],
      "metadata": {
        "id": "4uBPObnmo2NR"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "round(df['rouge-1'].mean(), 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcITZlNeo2VC",
        "outputId": "75c1c2a1-d1e5-4c7e-f224-5e6e451f08d1"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35.922"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "round(df['rouge-2'].mean(), 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKVHkPbuo2Y_",
        "outputId": "a1ffa31c-df00-4325-d6c6-915d07c16ee3"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31.15"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "round(df['rouge-l'].mean(), 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asXctgFco9A_",
        "outputId": "0622e189-62f7-474e-a716-ae43465a09ea"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26.701"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    }
  ]
}